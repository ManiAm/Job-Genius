# config.py

rag_search_url = "http://localhost:8000"

llm_model_summarization = "ollama/llama3.1:8b"
llm_model_chat = "gpt-4o"
embed_model = "bge-m3"
